import streamlit as st
import google.generativeai as genai
import json
import os
import re
from dotenv import load_dotenv
from utils import HSDataManager
from hs_search import lookup_hscode
import requests

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ë“± ì„¤ì •ê°’ ë¡œë“œ)
load_dotenv()

# Gemini API ì„¤ì •
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="HS í’ˆëª©ë¶„ë¥˜ ì±—ë´‡",  # ë¸Œë¼ìš°ì € íƒ­ ì œëª©
    page_icon="ğŸ“Š",  # ë¸Œë¼ìš°ì € íƒ­ ì•„ì´ì½˜
    layout="wide"  # í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ë„“ê²Œ ì„¤ì •
)

# ì‚¬ìš©ì ì •ì˜ CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
.main > div {
    display: flex;
    flex-direction: column;
    height: 85vh;  # ë©”ì¸ ì»¨í…Œì´ë„ˆ ë†’ì´ ì„¤ì •
}
.main > div > div:last-child {
    margin-top: auto;  # ë§ˆì§€ë§‰ ìš”ì†Œë¥¼ í•˜ë‹¨ì— ê³ ì •
}
.element-container:has(button) {
    background-color: #f0f2f6;  # ë²„íŠ¼ ì»¨í…Œì´ë„ˆ ë°°ê²½ìƒ‰
    padding: 10px;
    border-radius: 10px;
}
.stTextArea textarea {
    border-radius: 20px;  # ì…ë ¥ì°½ ëª¨ì„œë¦¬ ë‘¥ê¸€ê²Œ
    padding: 10px 15px;
    font-size: 16px;
    min-height: 50px !important;  # ìµœì†Œ ë†’ì´
    max-height: 300px !important;  # ìµœëŒ€ ë†’ì´
    height: auto !important;  # ìë™ ë†’ì´ ì¡°ì ˆ
    resize: vertical !important;  # ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œë§Œ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥
    overflow-y: auto !important;  # ë‚´ìš©ì´ ë§ì„ ë•Œ ìŠ¤í¬ë¡¤ í‘œì‹œ
}
</style>
""", unsafe_allow_html=True)

# HS ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™” (ìºì‹±ì„ í†µí•´ ì„±ëŠ¥ ìµœì í™”)
@st.cache_resource
def get_hs_manager():
    return HSDataManager()

# HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜
def clean_text(text):
    # HTML íƒœê·¸ ì œê±° (ë” ì—„ê²©í•œ ì •ê·œì‹ íŒ¨í„´ ì‚¬ìš©)
    text = re.sub(r'<[^>]+>', '', text)  # ëª¨ë“  HTML íƒœê·¸ ì œê±°
    text = re.sub(r'\s*</div>\s*$', '', text)  # ëì— ìˆëŠ” </div> íƒœê·¸ ì œê±°
    return text.strip()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []  # ì±„íŒ… ê¸°ë¡ ì €ì¥

if 'context' not in st.session_state:
    # ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì•ˆë‚´ ì¶”ê°€)
    st.session_state.context = """ë‹¹ì‹ ì€ HS í’ˆëª©ë¶„ë¥˜ ì „ë¬¸ê°€ë¡œì„œ ê´€ì„¸ì²­ì—ì„œ ì˜¤ëœ ê²½ë ¥ì„ ê°€ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë¬¼ì–´ë³´ëŠ” í’ˆëª©ì— ëŒ€í•´ ì•„ë˜ ì„¸ ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸ ìœ í˜•:
1. ì›¹ ê²€ìƒ‰(Web Search): ë¬¼í’ˆê°œìš”, ìš©ë„, ê¸°ìˆ ê°œë°œ, ë¬´ì—­ë™í–¥ ë“± ì¼ë°˜ ì •ë³´ íƒìƒ‰ì´ í•„ìš”í•œ ê²½ìš°.
2. HS ë¶„ë¥˜ ê²€ìƒ‰(HS Classification Search): HS ì½”ë“œ, í’ˆëª©ë¶„ë¥˜, ê´€ì„¸, ì„¸ìœ¨ ë“± HS ì½”ë“œ ê´€ë ¨ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°.
3. HS í•´ì„¤ì„œ ë¶„ì„(HS Manual Analysis): HS í•´ì„¤ì„œ, ê·œì •, íŒë¡€ ë“± ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°.

ì¤‘ìš” ì§€ì¹¨:
1. ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ëŠ” ë¬¼í’ˆì— ëŒ€í•´ ê´€ë ¨ì–´, ìœ ì‚¬í’ˆëª©, ëŒ€ì²´í’ˆëª©ë„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ HS ì½”ë“œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
2. í’ˆëª©ì˜ ì„±ë¶„, ìš©ë„, ê°€ê³µìƒíƒœ ë“±ì„ ê³ ë ¤í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ì‚¬ìš©ìê°€ íŠ¹ì • HS codeë¥¼ ì–¸ê¸‰í•˜ë©° ì§ˆë¬¸í•˜ëŠ” ê²½ìš°, ë‹µë³€ì— í•´ë‹¹ HS code í•´ì„¤ì„œ ë¶„ì„ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
4. ê´€ë ¨ ê·œì •ì´ë‚˜ íŒë¡€ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”.
5. ë‹µë³€ì€ ê°„ê²°í•˜ë©´ì„œë„ ì „ë¬¸ì ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.

ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”:
"""

import re

# ëª¨ë“ˆ ìƒë‹¨ì—ì„œ í•œ ë²ˆë§Œ ì»´íŒŒì¼
HS_PATTERN = re.compile(
    r'\b(?:HS)?\s*\d{4}(?:[.-]\d{2}(?:[.-]\d{2}(?:[.-]\d{2})?)?)?\b',
    flags=re.IGNORECASE
)

def extract_hs_codes(text):
    """ì—¬ëŸ¬ HS ì½”ë“œë¥¼ ì¶”ì¶œí•˜ê³ , ì¤‘ë³µ ì œê±° ë° ìˆ«ìë§Œ ë‚¨ê²¨ í‘œì¤€í™”"""
    matches = HS_PATTERN.findall(text)
    hs_codes = []
    for raw in matches:
        # ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
        code = re.sub(r'\D', '', raw)
        if code and code not in hs_codes:
            hs_codes.append(code)
    return hs_codes

import json

def extract_and_store_text(json_file):
    """JSON íŒŒì¼ì—ì„œ head1ê³¼ textë¥¼ ì¶”ì¶œí•˜ì—¬ ë³€ìˆ˜ì— ì €ì¥"""
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(json_file, 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        # ë°ì´í„°ë¥¼ ë³€ìˆ˜ì— ì €ì¥
        extracted_data = []
        for item in data:
            head1 = item.get('head1', '')
            text = item.get('text', '')
            if head1 or text:
                extracted_data.append(f"{head1}\n{text}")
        
        # print("ë°ì´í„°ê°€ ë³€ìˆ˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return extracted_data
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# í•¨ìˆ˜ ì‹¤í–‰ ë° ë°ì´í„° ì €ì¥
general_explanation = extract_and_store_text('knowledge/í†µì¹™_grouped.json')


def get_hs_explanations(hs_codes):
    """ì—¬ëŸ¬ HS ì½”ë“œì— ëŒ€í•œ í•´ì„¤ì„ ì·¨í•©í•˜ëŠ” í•¨ìˆ˜"""
    all_explanations = ""
    for hs_code in hs_codes:
        explanation, type_explanation, number_explanation = lookup_hscode(hs_code, 'knowledge/grouped_11_end.json')

        if explanation and type_explanation and number_explanation:
            all_explanations += f"\n\nHS ì½”ë“œ {hs_code}ì— ëŒ€í•œ í•´ì„¤:\n"
            all_explanations += f"í•´ì„¤ì„œ í†µì¹™:\n{general_explanation}\n\n"
            all_explanations += f"ë¶€ í•´ì„¤:\n{explanation['text']}\n\n"
            all_explanations += f"ë¥˜ í•´ì„¤:\n{type_explanation['text']}\n\n"
            all_explanations += f"í˜¸ í•´ì„¤:\n{number_explanation['text']}\n"
    return all_explanations

# Serper APIë¥¼ ì´ìš©í•œ ì›¹ ê²€ìƒ‰ ë‹µë³€ í•¨ìˆ˜
def web_search_answer(query, num_results=3):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ Serper APIë¥¼ ì´ìš©í•´ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    (Serper API í‚¤ í•„ìš”, https://serper.dev)
    """
    SERPER_API_KEY = os.getenv('SERPER_API_KEY')
    if not SERPER_API_KEY:
        return "ì›¹ ê²€ìƒ‰ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    endpoint = "https://google.serper.dev/search"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "q": query,
        "num": num_results
    }
    try:
        response = requests.post(endpoint, headers=headers, json=payload)
        response.raise_for_status()
        results = response.json().get("organic", [])
        if not results:
            return "ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        answer = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:\n"
        for idx, item in enumerate(results, 1):
            title = re.sub(r'<.*?>', '', item.get("title", ""))
            snippet = re.sub(r'<.*?>', '', item.get("snippet", ""))
            url = item.get("link", "")
            answer += f"{idx}. [{title}]({url}): {snippet}\n"
        return answer
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜ (LLM ê¸°ë°˜)
def classify_question(user_input):
    """
    LLM(Gemini)ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì•„ë˜ ì„¸ ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - 'web_search': ë¬¼í’ˆ ê°œìš”, ìš©ë„, ê¸°ìˆ ê°œë°œ, ë¬´ì—­ë™í–¥, ì‚°ì—…ë™í–¥ ë“±
    - 'hs_classification': HS ì½”ë“œ, í’ˆëª©ë¶„ë¥˜, ê´€ì„¸ ë“±
    - 'hs_manual': HS í•´ì„¤ì„œ, ê·œì •, íŒë¡€ ë“± ì‹¬ì¸µ ë¶„ì„
    """
    system_prompt = """
ì•„ë˜ëŠ” HS í’ˆëª©ë¶„ë¥˜ ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ê¸°ì¤€ì…ë‹ˆë‹¤.

ì§ˆë¬¸ ìœ í˜•:
1. "web_search" : "ë‰´ìŠ¤", "ìµœê·¼", "ë™í–¥", "í•´ì™¸", "ì‚°ì—…, ê¸°ìˆ , ë¬´ì—­ë™í–¥" ë“± ì¼ë°˜ ì •ë³´ íƒìƒ‰ì´ í•„ìš”í•œ ê²½ìš°.
2. "hs_classification": HS ì½”ë“œ, í’ˆëª©ë¶„ë¥˜, ê´€ì„¸, ì„¸ìœ¨ ë“± HS ì½”ë“œ ê´€ë ¨ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°.
3. "hs_manual": HS í•´ì„¤ì„œ, ê·œì •, íŒë¡€ ë“± ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°.

ì•„ë˜ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì½ê³ , ë°˜ë“œì‹œ ìœ„ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ìœ í˜•ë§Œ í•œê¸€ì´ ì•„ë‹Œ ì†Œë¬¸ì ì˜ë¬¸ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
ì§ˆë¬¸: """ + user_input + """\në‹µë³€:"""

    model = genai.GenerativeModel('gemini-2.0-flash')
    response = model.generate_content(system_prompt)
    answer = response.text.strip().lower()
    # ê²°ê³¼ê°€ ì •í™•íˆ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì¸ì§€ í™•ì¸
    if answer in ["web_search", "hs_classification", "hs_manual"]:
        return answer
    # ì˜ˆì™¸ ì²˜ë¦¬: ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    return "hs_classification"

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì½œë°± í•¨ìˆ˜ (ìˆ˜ì •)

def handle_web_search(user_input, context, hs_manager):
    relevant = hs_manager.get_relevant_context(user_input)
    search_result = web_search_answer(user_input)
    prompt = f"{context}\n\nê´€ë ¨ ë°ì´í„°:\n{relevant}\n{search_result}\n\nì‚¬ìš©ì: {user_input}\n"
    model = genai.GenerativeModel('gemini-2.0-flash')
    resp = model.generate_content(prompt)
    return clean_text(resp.text)

def handle_hs_classification_cases(user_input, context, hs_manager):
    relevant = hs_manager.get_relevant_context(user_input)
    # hs_codes = extract_hs_codes(user_input)
    # explanations = get_hs_explanations(hs_codes) if hs_codes else ""
    prompt = f"{context}\n\nê´€ë ¨ ë°ì´í„°:\n{relevant}\n\nì‚¬ìš©ì: {user_input}\n"
    model = genai.GenerativeModel('gemini-2.0-flash')
    resp = model.generate_content(prompt)
    return clean_text(resp.text)

def handle_hs_manual(user_input, context, hs_manager):
    # ì˜ˆ: HS í•´ì„¤ì„œ ë¶„ì„ ì „ìš© ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    manual_context = context + "\n(ì‹¬ì¸µ í•´ì„¤ì„œ ë¶„ì„ ëª¨ë“œ)"
    # relevant = hs_manager.get_relevant_context(user_input)
    hs_codes = extract_hs_codes(user_input)
    explanations = get_hs_explanations(hs_codes) if hs_codes else ""
    prompt = f"{manual_context}\n\nê´€ë ¨ ë°ì´í„°:\n{explanations}\n\nì‚¬ìš©ì: {user_input}\n"
    model = genai.GenerativeModel('gemini-2.0-flash')
    resp = model.generate_content(prompt)
    return clean_text(resp.text)

def process_input():
    ui = st.session_state.user_input
    if not ui: 
        return

    st.session_state.chat_history.append({"role": "user", "content": ui})
    hs_manager = get_hs_manager()
    q_type = classify_question(ui)

    # ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ê¸°
    if q_type == "web_search":
        answer = handle_web_search(ui, st.session_state.context, hs_manager)
    elif q_type == "hs_classification":
        answer = handle_hs_classification_cases(ui, st.session_state.context, hs_manager)
    elif q_type == "hs_manual":
        answer = handle_hs_manual(ui, st.session_state.context, hs_manager)
    else:
        # ì˜ˆì™¸ ì²˜ë¦¬: ê¸°ë³¸ HS ë¶„ë¥˜
        answer = handle_hs_classification_cases(ui, st.session_state.context, hs_manager)

    st.session_state.chat_history.append({"role": "assistant", "content": answer})
    st.session_state.context += f"\nì‚¬ìš©ì: {ui}\ní’ˆëª©ë¶„ë¥˜ ì „ë¬¸ê°€: {answer}\n"
    st.session_state.user_input = ""


# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("HS Chatbot")
    st.markdown("""
    ### ì´ê²ƒì€ HS Chatbotì…ë‹ˆë‹¤.

    ì´ ì±—ë´‡ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤:

    - **ì›¹ ê²€ìƒ‰(Web Search)**: ë¬¼í’ˆê°œìš”, ìš©ë„, ë‰´ìŠ¤, ë¬´ì—­ë™í–¥, ì‚°ì—…ë™í–¥ ë“± ì¼ë°˜ ì •ë³´ íƒìƒ‰ì´ í•„ìš”í•œ ê²½ìš° Serper APIë¥¼ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    - **HS ë¶„ë¥˜ ê²€ìƒ‰(HS Classification Search)**: ê´€ì„¸ì²­ì˜ í’ˆëª©ë¶„ë¥˜ ì‚¬ë¡€ ì•½ 1000ê°œì˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ HS ì½”ë“œ, í’ˆëª©ë¶„ë¥˜, ê´€ì„¸, ì„¸ìœ¨ ë“± ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    - **HS í•´ì„¤ì„œ ë¶„ì„(HS Manual Analysis)**: HS í•´ì„¤ì„œ, ê·œì •, íŒë¡€ ë“± ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° ê´€ë ¨ í•´ì„¤ì„œì™€ ê·œì •ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìëŠ” HS ì½”ë“œ, í’ˆëª© ë¶„ë¥˜, ì‹œì¥ ë™í–¥, ê·œì • í•´ì„¤ ë“± ë‹¤ì–‘í•œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    # ìƒˆë¡œìš´ ì±„íŒ… ì‹œì‘ ë²„íŠ¼
    if st.button("ìƒˆë¡œìš´ ì±„íŒ… ì‹œì‘í•˜ê¸°", type="primary"):
        st.session_state.chat_history = []  # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
        st.session_state.context = """ë‹¹ì‹ ì€ HS í’ˆëª©ë¶„ë¥˜ ì „ë¬¸ê°€ë¡œì„œ ê´€ì„¸ì²­ì—ì„œ ì˜¤ëœ ê²½ë ¥ì„ ê°€ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë¬¼ì–´ë³´ëŠ” í’ˆëª©ì— ëŒ€í•´ ì•„ë˜ ì„¸ ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸ ìœ í˜•:
1. ì›¹ ê²€ìƒ‰(Web Search): ë¬¼í’ˆê°œìš”, ìš©ë„, ë‰´ìŠ¤, ë¬´ì—­ë™í–¥, ì‚°ì—…ë™í–¥ ë“± ì¼ë°˜ ì •ë³´ íƒìƒ‰ì´ í•„ìš”í•œ ê²½ìš°.
2. HS ë¶„ë¥˜ ê²€ìƒ‰(HS Classification Search): HS ì½”ë“œ, í’ˆëª©ë¶„ë¥˜, ê´€ì„¸, ì„¸ìœ¨ ë“± HS ì½”ë“œ ê´€ë ¨ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°.
3. HS í•´ì„¤ì„œ ë¶„ì„(HS Manual Analysis): HS í•´ì„¤ì„œ, ê·œì •, íŒë¡€ ë“± ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°.

ì¤‘ìš” ì§€ì¹¨:
1. ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ëŠ” ë¬¼í’ˆì— ëŒ€í•´ ê´€ë ¨ì–´, ìœ ì‚¬í’ˆëª©, ëŒ€ì²´í’ˆëª©ë„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ HS ì½”ë“œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
2. í’ˆëª©ì˜ ì„±ë¶„, ìš©ë„, ê°€ê³µìƒíƒœ ë“±ì„ ê³ ë ¤í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
3. ì‚¬ìš©ìê°€ íŠ¹ì • HS codeë¥¼ ì–¸ê¸‰í•˜ë©° ì§ˆë¬¸í•˜ëŠ” ê²½ìš°, ë‹µë³€ì— í•´ë‹¹ HS code í•´ì„¤ì„œ ë¶„ì„ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
4. ê´€ë ¨ ê·œì •ì´ë‚˜ íŒë¡€ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”.
5. ë‹µë³€ì€ ê°„ê²°í•˜ë©´ì„œë„ ì „ë¬¸ì ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.

ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”:
"""
        st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

# ë©”ì¸ í˜ì´ì§€ ì„¤ì •
st.title("HS í’ˆëª©ë¶„ë¥˜ ì±—ë´‡")
st.write("HS í’ˆëª©ë¶„ë¥˜ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!")

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.chat_history:
    if message["role"] == "user":
        st.markdown(f"""<div style='background-color: #e6f7ff; padding: 10px; border-radius: 10px; margin-bottom: 10px;'>
                   <strong>ì‚¬ìš©ì:</strong> {message['content']}
                   </div>""", unsafe_allow_html=True)
    else:
        st.markdown(f"""<div style='background-color: #f0f2f6; padding: 10px; border-radius: 10px; margin-bottom: 10px;'>
                   <strong>í’ˆëª©ë¶„ë¥˜ ì „ë¬¸ê°€:</strong> {message['content']}
                   </div>""", unsafe_allow_html=True)


# í•˜ë‹¨ ì…ë ¥ ì˜ì—­ (Enter í‚¤ë¡œë§Œ ì „ì†¡)
input_container = st.container()
st.markdown("<div style='flex: 1;'></div>", unsafe_allow_html=True)

with input_container:
    # on_change ì½œë°±ìœ¼ë¡œ Enter ëˆ„ë¥¼ ë•Œ process_input() í˜¸ì¶œ
    st.text_input(
        "í’ˆëª©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:", 
        key="user_input", 
        on_change=process_input, 
        placeholder="ì—¬ê¸°ì— ì…ë ¥ í›„ Enter"
    )
